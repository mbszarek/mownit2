{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_path = 'hamlet.txt'\n",
    "with open(hamlet_path, 'r') as hamlet:\n",
    "    lines = hamlet.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the tragedy of hamlet, prince of denmark',\n",
       " 'by william shakespeare',\n",
       " 'dramatis personae',\n",
       " 'claudius, king of denmark.',\n",
       " 'marcellus, officer.',\n",
       " 'hamlet, son to the former, and nephew to the present king.',\n",
       " 'polonius, lord chamberlain.',\n",
       " 'horatio, friend to hamlet.',\n",
       " 'laertes, son to polonius.',\n",
       " 'voltemand, courtier.',\n",
       " 'cornelius, courtier.',\n",
       " 'rosencrantz, courtier.',\n",
       " 'guildenstern, courtier.',\n",
       " 'osric, courtier.',\n",
       " 'a gentleman, courtier.',\n",
       " 'a priest.',\n",
       " 'marcellus, officer.',\n",
       " 'bernardo, officer.',\n",
       " 'francisco, a soldier',\n",
       " 'reynaldo, servant to polonius.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [i.strip().lower() for i in lines if i.strip()]\n",
    "lines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4163"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posiadamy około 4100 linii z Hamleta, podzielimy to na 500 dokumentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = defaultdict(list)\n",
    "bag_of_words = set()\n",
    "\n",
    "index = 0\n",
    "\n",
    "for i, value in enumerate(lines):\n",
    "    documents[index] += value.split()\n",
    "    bag_of_words |= set(value.split())\n",
    "    if (i + 1) % 8 == 0:\n",
    "        index += 1\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie obliczmy częstotliwość wystąpienia słowa dla każdego dokumentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = []\n",
    "for _, words_list in documents.items():\n",
    "    bag_of_words_for_doc = dict.fromkeys(bag_of_words, 0)\n",
    "    for word in words_list:\n",
    "        bag_of_words_for_doc[word] += 1\n",
    "    freq.append(bag_of_words_for_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-by-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_by_document():\n",
    "    amount_of_words = len(bag_of_words)\n",
    "    res = np.zeros(shape=(amount_of_words, 558))\n",
    "    for i in range(558):\n",
    "        for index, word in enumerate(list(bag_of_words)):\n",
    "            res[index, i] = freq[i][word]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_by_document_matrix = term_by_document()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF - redukcja często występujących słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_words = len(bag_of_words)\n",
    "idf = []\n",
    "for index, words_list in enumerate(list(bag_of_words)):\n",
    "    words_num = 0\n",
    "    for i in range(558):\n",
    "        if term_by_document_matrix[index, i] > 0:\n",
    "            words_num += 1\n",
    "    if words_num > 0:\n",
    "        idf.append(np.log10(558 / words_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Znajdowanie $k$ dokumentów zbliżonych do zapytania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_of_similarity(sentence, k):\n",
    "    query = sentence.strip().lower().split()\n",
    "    \n",
    "    q = np.zeros(amount_of_words)\n",
    "    j = 0\n",
    "    for word in query:\n",
    "        if word in bag_of_words:\n",
    "            q[j] = 1\n",
    "        j += 1\n",
    "    similarity_rate = {}\n",
    "    for i in range(558):\n",
    "        dj = term_by_document_matrix[:,[i]]\n",
    "        q_norm = np.linalg.norm(q)\n",
    "        dj_norm = np.linalg.norm(dj)\n",
    "        cosj = np.dot(q,dj)/(q_norm*dj_norm)\n",
    "        similarity_rate.update({i:cosj})\n",
    "        \n",
    "    return nlargest(k, similarity_rate, key=similarity_rate.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"For food and diet\"\n",
    "simple = rate_of_similarity(sentence, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[230, 507, 264, 0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(term_by_document_matrix, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "np.allclose(term_by_document_matrix, np.dot(U, np.dot(S, V)))\n",
    "term_by_document_matrix = np.dot(U, np.dot(S, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[230, 507, 264, 521, 390, 261, 395, 295, 109, 209]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withSVD = rate_of_similarity(sentence, 10)\n",
    "withSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Na koniec IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[230, 507, 264, 521, 390, 261, 256, 512, 295, 365]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(558):\n",
    "    for j in range(len(idf)):\n",
    "        term_by_document_matrix[j, i] *= idf[j]\n",
    "        \n",
    "withIDF = rate_of_similarity(sentence, 10)\n",
    "withIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wnioski\n",
    "Wszystkie metody się różnią ostatnimi elementami listy, natomiast początkowe są takie same. Świadczy to o poprawności implementacji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
